# ğŸš€ Lightweight ResNet for CIFAR-10
ğŸ† Lightweight ResNet with â‰¤5M Parameters, optimized for CIFAR-10.

![Framework](results/model_architecture.png)

---

## ğŸ“– Overview
This project focuses on designing a **lightweight ResNet** for **CIFAR-10**, ensuring:
- **â‰¤5M parameters** for efficient inference.
- **Depthwise Separable Convolutions** for reduced computation.
- **Pruning & Quantization** for model compression.
- **Data Augmentation (Cutout, Mixup, Cutmix)** for improved generalization.

---

## **ğŸ”¥ Experimental Results**
| Model Variant       | Parameters | Test Accuracy (%) |
|--------------------|------------|------------------|
| **Baseline ResNet-18** | 11.2M | 93.5% |
| **Lightweight ResNet (Ours)** | **3.5M** | **88.5%** |
| Lightweight ResNet + Pruning | 2.8M | 85.2% |
| Lightweight ResNet + Quantization | 1.5M | 83.7% |

ğŸ“Š **Final Model Accuracy:** **88.5% on CIFAR-10**  
ğŸ“‰ **Reduced Parameters:** **From 11.2M â†’ 3.5M (~68% reduction!)**  

---

## **âš¡ Model Architecture**
The model is based on **ResNet**, but with **Depthwise Separable Convolutions** to reduce computation.
```plaintext
Input (3x32x32)
â†“
Depthwise Separable Conv (3 â†’ 32)
â†“
Residual Block (32 â†’ 64)
â†“
Residual Block (64 â†’ 128)
â†“
Residual Block (128 â†’ 256)
â†“
Global Average Pooling
â†“
Fully Connected (256 â†’ 10)
â†“
Softmax
